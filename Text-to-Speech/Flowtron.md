# Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis

## Original paper: https://arxiv.org/pdf/2005.05957.pdf

### Abstract

Trong bài báo này, tác giả đề xuất Flowtron: một mạng generative dựa trên luồng hồi quy tự động để tổng hợp văn bản thành giọng nói với sự kiểm soát về biến đổi giọng nói và chuyển kiểu nói. Flowtron sử dụng những kiến thức chuyên sâu từ IAF và cải tiến Tacotron để tổng hợp lên melspectrogram chất lượng cao và biểu cảm. Flowtron được tối ưu hóa bằng cách tối đa hóa khả năng của dữ liệu đào tạo, giúp đào tạo đơn giản và ổn định. Flowtron học cách ánh xạ dữ liệu có thể đảo ngược tới một không gian tiềm ẩn để có thể kiểm soát nhiều khía cạnh của tổng hợp giọng nói (cao độ, âm điệu, tốc độ nói, nhịp, trọng âm). Điểm số ý kiến trung bình (MOS) cho thấy Flowtron phù hợp với các mô hình TTS hiện đại về chất lượng giọng nói. Ngoài ra, tác giả cung cấp kết quả về kiểm soát sự biến đổi giọng nói, nội suy giữa các mẫu và chuyển kiểu nói giữa những người nói có mặt và không có mặt trong quá trình đào tạo. 

### Introduction

Các phương pháp tổng hợp giọng nói hiện tại không cung cấp cho người dùng đủ quyền kiểm soát cách giọng nói thực sự phát ra. Tự động chuyển đổi văn bản sang âm thanh đã đạt được những thành công cách đây rất lâu. Tuy nhiên, chỉ truyền đạt thông tin văn bản sẽ loại bỏ tất cả các đặc tính âm thanh của giọng nói, vốn truyền tải nhiều ý nghĩa và biểu cảm của con người. Gần như tất cả các nghiên cứu về tổng hợp giọng nói từ những năm 1960 đều tập trung vào việc thêm thông tin phi văn bản đó vào tổng hợp lời nói. Nhưng mặc dù vậy, vấn đề tổng hợp giọng nói điển hình được xây dựng như một vấn đề chuyển văn bản thành giọng nói trong đó người dùng chỉ nhập văn bản. 

Việc huấn luyện hóa thông tin phi văn bản trong lời nói là một việc khó khăn, bởi vì phi văn bản không được gắn nhãn. Người nói có thể nói cùng một văn bản với sự nhấn mạnh hoặc cảm xúc khác nhau dựa trên ngữ cảnh, nhưng không có một cách nào gán nhãn cụ thể đối với dữ liệu đó. Không có nhãn cho thông tin không phải dạng văn bản, các mô hình đã rơi vào trạng thái học tập không có giám sát. Các mô hình gần đây đã đạt được chất lượng gần như cấp độ nói của con người, mặc dù coi thông tin phi văn bản như một hộp đen. Mục tiêu duy nhất của mô hình là khớp với các mẫu trong dữ liệu đào tạo. Dù các mô hình có khả năng tái tạo lại thông tin phi văn bản trong tập huấn luyện, người dùng vẫn không có được cái nhìn chính xác hay sự kiểm soát những thông tin phi văn bản đó.

Tác giả xây dựng một bài toán học tập không giám sát mà theo cách đó, người dùng có thể hiểu sâu hơn về cấu trúc của tập dữ liệu. Trong đó, dữ liệu được giả định là có một biểu diễn trong một không gian tiềm ẩn nào đó và để mô hình học cách biểu diễn đó. Sau đó, không gian tiềm ẩn này có thể được phân tích và xử lý để cung cấp cho người dùng nhiều quyền kiểm soát hơn đối với đầu ra của mô hình generative. Những cách tiếp cận như vậy đã phổ biến trong mảng tạo hình ảnh, cho phép người dùng nội suy giữa các hình ảnh dễ dàng và xác định các phần của không gian tiềm ẩn tương quan với các feature khác nhau.

Tuy nhiên, đối với âm thanh, các phương pháp tiếp cận đã tập trung vào việc nhúng (embedding) để loại bỏ một lượng lớn thông tin và thu được từ các giả định về những gì quan trọng. Các phương pháp tiếp cận gần đây sử dụng học sâu để tổng hợp giọng nói biểu cảm, kết hợp giữa văn bản và mô hình nhúng tiềm ẩn đã được huấn luyện, dùng cho giọng điệu hoặc sự đa dạng cách đọc. Một biến thể của phương pháp này được đề xuất bởi (Hsu 2018), trong đó mô hình hỗn hợp Gaussian (GMM) mã hóa âm thanh được thêm vào Tacotron để học cách nhúng tiềm ẩn. Những cách tiếp cận này kiểm soát thông tin phi văn bản bằng cách học một chuỗi nhúng hoặc bằng cách cung cấp đầu ra mục tiêu làm đầu vào cho mô hình và nén nó. Tuy nhiên, các cách tiếp cận này yêu cầu đưa ra các giả định về kích thước của các bản nhúng trước khi thực hiện và không được đảm bảo chứa được tất cả thông tin phi văn bản cần thiết để tái tạo lại lời nói, bao gồm cả nguy cơ có kích thước không chính xác hoặc không đủ dung lượng, như phần phụ lục đã xác nhận. Chúng cũng yêu cầu có một bộ mã hóa và nhúng để ngăn mô hình chỉ đơn giản là học một hàm nhận dạng phức tạp mà bỏ qua các đầu vào khác. Hơn nữa, những cách tiếp cận này tập trung vào các embedding có độ dài cố định với giả định rằng các embedding có độ dài thay đổi không tác động mạnh đối với nhiễu của văn bản và diễn giả. Cuối cùng, hầu hết các cách tiếp cận này không cung cấp cho người dùng quyền kiểm soát mức độ thay đổi trong tổng hợp tiếng nói.

Trong bài báo này, tác giả đề xuất Flowtron: một mạng generative dựa trên luồng tự động hồi quy để tổng hợp quang phổ mel với khả năng kiểm soát âm học và giọng nói. Flowtron học một hàm có thể đảo ngược, ánh xạ phân phối qua melspectrograms tới một không gian tiềm ẩn z được tham số hóa bởi Gaussian hình cầu. Với việc chính thức hóa này, tác giả có thể tạo các mẫu chứa đặc điểm lời nói cụ thể được biểu hiện trong mel-space bằng cách tìm và lấy mẫu vùng tương ứng trong z-space. Trong cách tiếp cận cơ bản, tác giả tạo mẫu bằng cách lấy mẫu zero mean spherical Gaussian trước đó và kiểm soát lượng biến thiên bằng cách điều chỉnh phương sai của nó. Mặc dù đơn giản, phương pháp này cung cấp nhiều biến thể và khả năng kiểm soát giọng nói hơn Tacotron.

Trong Flowtron, chúng ta có thể truy cập các khu vực cụ thể của không gian melspectrogram bằng cách lấy mẫu phân bố phía sau với điều kiện dựa trên dấu hiệu trước đó từ các mẫu hiện có. Cách tiếp cận này cho phép chúng ta làm cho một người nói đơn điệu trở nên biểu cảm hơn bằng cách tính toán vùng trong không gian z liên kết với lời nói biểu cảm, như nó được thể hiện trong dấu hiệu trước đó. Cuối cùng, công thức của tác giả cũng cho phép chúng ta áp đặt một cấu trúc cho không gian z và tham số hóa nó với một hỗn hợp Gauss. Cách tiếp cận này liên quan đến (Hsu 2018), đặc điểm giọng nói trong không gian quang phổ mel có thể được liên kết với các thành phần riêng lẻ. Do đó, có thể tạo ra các mẫu với các đặc điểm giọng nói cụ thể bằng cách chọn ra một thành phần hoặc hỗn hợp của chúng. 

Mặc dù các mô hình dựa trên VAEs và GAN ​​(Hsu et al., 2018; Binkowski et al., 2019; Akuzawa et al., 2018) cũng cung cấp tiềm ẩn trước đó, có thể dễ dàng điều khiển. Trong Flowtron, điều này không làm giảm chất lượng giọng nói mà vẫn giữ được hiệu năng tốt.

Tác giả thấy rằng Flowtron có thể tổng quát hóa và tạo ra các phổ mel sắc nét bằng cách đơn giản là tối đa hóa khả năng của dữ liệu trong khi không yêu cầu bất kỳ lớp Prenet hoặc Postnet bổ sung nào (Wang et al., 2017), cũng như các hàm mất mát phức hợp được yêu cầu bởi hầu hết các mô hình State-of-the-art như (Shen et al., 2017; Arik et al., 2017b;a; Ping et al., 2017; Skerry-Ryan et al., 2018; Wang et al., 2018; Binkowski et al., 2019). 

Flowtron được tối ưu hóa bằng cách tối đa hóa khả năng của dữ liệu huấn luyện, giúp việc huấn luyện trở nên đơn giản và ổn định. Nó học một ánh xạ có thể đảo ngược của một không gian tiềm ẩn, có thể được điều khiển để kiểm soát nhiều khía cạnh của tổng hợp giọng nói. MOS cho thấy Flowtron tương đương với các mô hình TTS hiện đại về chất lượng giọng nói. Ngoài ra, tác giả cung cấp kết quả về kiểm soát sự thay đổi giọng nói, nội suy giữa các mẫu và chuyển kiểu nói giữa người nói có mặt/không có mặt trong dữ liệu bằng các câu giống nhau và khác nhau. Theo hiểu biết của tác giả, công trình này là công trình đầu tiên cho thấy bằng chứng rằng việc chuẩn hóa các mô hình luồng cũng có thể được sử dụng để tổng hợp văn bản thành giọng nói. Tác giả hy vọng điều này sẽ tiếp tục kích thích sự phát triển trong việc chuẩn hóa luồng (normalizing flows).

### Related Work

Các phương pháp tổng hợp văn bản thành giọng nói trước đây đạt được kết quả giống như con người tập trung vào việc tổng hợp các đặc điểm âm thanh từ văn bản, coi thông tin phi văn bản như một hộp đen. (Shen và cộng sự, 2017; Arik và cộng sự, 2017b; a; Ping và cộng sự, 2017). Các phương pháp như (Wang và cộng sự, 2017; Shen và cộng sự, 2017) yêu cầu thêm một lớp Prenet quan trọng để giúp hội tụ và cải thiện tính tổng quát (Wang và cộng sự, 2017). Hơn nữa, các mô hình như vậy yêu cầu một lớp dư Postnet bổ sung và tổn thất được sửa đổi để tạo ra "các sóng hài được phân giải tốt hơn và cấu trúc định dạng tần số cao, làm giảm các hiện vật tổng hợp." Một cách tiếp cận để giải quyết vấn đề thiếu nhãn cho thông tin phi văn bản cơ bản là tìm kiếm số liệu thống kê được thiết kế thủ công dựa trên âm thanh mà chúng tôi tin rằng có tương quan với thông tin cơ bản này. Đây là cách tiếp cận được thực hiện bởi các mô hình như (Nishimura và cộng sự, 2016; Lee và cộng sự, 2019), trong đó lời nói được điều chỉnh dựa trên thống kê âm thanh có thể được tính toán trực tiếp từ dữ liệu đào tạo như F0 (tần số cơ bản). Tuy nhiên, để sử dụng các mô hình như vậy, các thống kê mà chúng ta hy vọng là gần đúng phải được quyết định dựa trên tiên nghiệm, và giá trị mục tiêu của các thống kê này phải được xác định trước khi tổng hợp. Một cách tiếp cận khác để giải quyết vấn đề thông tin phi văn bản không được gắn nhãn là tìm hiểu cách nhúng tiềm ẩn cho phong cách ưu việt hoặc toàn cầu. Đây là cách tiếp cận được thực hiện bởi các mô hình như (Skerry-Ryan và cộng sự, 2018; Wang và cộng sự, 2018), trong đó trong một ngân hàng nhúng hoặc không gian nhúng tiềm ẩn của prosody được học từ dữ liệu không được gắn nhãn. Mặc dù những cách tiếp cận này đã cho thấy nhiều hứa hẹn, nhưng việc vận dụng các biến tiềm ẩn như vậy chỉ mang lại sự kiểm soát thô đối với các đặc điểm biểu đạt của lời nói.